#!/usr/bin/env python
# -*- coding: utf-8

import os
import sys
import random
import string
import tempfile
import argparse
import subprocess
import configparser

from colored import style, fore

# pointer_file contains a single line which is the path to the clusterize config file
# this is so multiple users can point to the same shared cluster config by changing their
# individual clusterize_pointer files
pointer_file = os.path.join(os.path.expanduser('~'), '.clusterize_pointer')
default_config_path = os.path.join(os.path.expanduser('~'), '.clusterize_config')
if not os.path.exists(pointer_file):
    with open(pointer_file, 'w') as f:
        f.write(default_config_path)

SBATCH_template = """#!/bin/bash
#SBATCH --job-name={job_name}
#SBATCH --output={output}
#SBATCH --error={error}
#SBATCH --partition={partition}
#SBATCH --nodes={num_nodes}
#SBATCH --ntasks-per-node={num_tasks_per_node}
#SBATCH --time={allotted_time}
#SBATCH --mem-per-cpu={mem_per_cpu}

{command}
"""

out_of_box_defaults = {
    'job_name': 'clusterize',
    'partition': None,
    'num_nodes': 1,
    'num_tasks_per_node': 1,
    'allotted_time': '4-0:00:00',
    'mem_per_cpu': 10000,
    'dont_add_random_string_to_job_name_and_outputs': 0,
}


class Clusterize(object):
    def __init__(self, args):
        self.job_seed = self.get_job_seed()

        self.config_file_path = open(pointer_file, 'r').readline().strip()
        self.config_file_exists = True if os.path.exists(self.config_file_path) else False

        if not self.config_file_exists:
            if self.config_file_path == default_config_path:
                get_default_config(self.config_file_path)
            else:
                print(fore.RED + '{} does not exist. Try setting a new config file'.format(self.config_file_path))
                sys.exit()

        self.user_defaults = {}

        A = lambda x, d: args.__dict__.get(x, None) if args.__dict__.get(x, None) is not None else d(x)
        self.params = {
            'command': A('command', self.get_default),
            'job_name': A('job_name', self.get_default),
            'output': A('output', lambda x: A('job_name', self.get_default) + '.log'),
            'error': A('error', lambda x: A('job_name', self.get_default) + '.log'),
            'partition': A('partition', self.get_default),
            'num_nodes': A('num_nodes', self.get_default),
            'num_tasks_per_node': A('num_tasks_per_node', self.get_default),
            'allotted_time': A('allotted_time', self.get_default),
            'mem_per_cpu': A('mem_per_cpu', self.get_default),
            'dont_add_random_string_to_job_name_and_outputs': bool(int(A('dont_add_random_string_to_job_name_and_outputs', self.get_default))),
            'seed': self.job_seed,
        }

        if not self.params['dont_add_random_string_to_job_name_and_outputs']:
            self.params['job_name'] += '_' + self.params['seed']

            # adds string before last `.` (if it exists) to keep file extension
            job_out_split, job_err_split = self.params['output'].split('.'), self.params['error'].split('.')

            if '.' in self.params['output']:
                split_by_dot = self.params['output'].split('.')
                split_by_dot[-2] += '_' + self.params['seed']
                self.params['output'] = '.'.join(split_by_dot)
            else:
                self.params['output'] += '_' + self.params['seed']

            if '.' in self.params['error']:
                split_by_dot = self.params['error'].split('.')
                split_by_dot[-2] += '_' + self.params['seed']
                self.params['error'] = '.'.join(split_by_dot)
            else:
                self.params['error'] += '_' + self.params['seed']

        self.sbatch_filepath = self.gen_sbatch_file()

        self.run_job()


    def get_job_seed(self, length=10):
        letters = string.ascii_letters
        return ''.join(random.choice(letters) for i in range(length))


    def touch(self, path):
        if os.path.exists(path):
            pass
        else:
            open(path, 'a').close()


    def run_job(self):
        cmd = 'sbatch {}'.format(self.sbatch_filepath)

        try:
            output = subprocess.check_output(cmd, shell=True, universal_newlines=True)
        except subprocess.CalledProcessError as e:
            print(fore.RED + 'ClusterizeError shown above. Change parameters or edit {}'.format(self.config_file_path) + style.RESET)
        finally:
            os.remove(self.sbatch_filepath)

        self.touch(self.params['output'])
        self.touch(self.params['error'])

        extra_msg = ''
        if self.params['output'] == self.params['error']:
            extra_msg += ' (log: {})'.format(self.params['output'])
        else:
            extra_msg += ' (logs: {}, {})'.format(self.params['output'], self.params['error'])

        print(fore.GREEN + str(output.strip()) + extra_msg + style.RESET)


    def gen_sbatch_file(self, filepath=None):
        if not filepath:
            f = tempfile.NamedTemporaryFile(delete = False, prefix = 'clusterize_' + self.job_seed + '_')
            filepath = f.name
            f.close()

        file_as_str = SBATCH_template.format(**self.params)
        with open(filepath, 'w') as f:
            f.write(file_as_str)

        return filepath


    def get_default(self, param_name):
        if self.config_file_exists and not self.user_defaults:
            config = configparser.ConfigParser()
            config.read(self.config_file_path)
            for k, v in config['CLUSTERIZE_DEFAULTS'].items():
                self.user_defaults[k] = v
        else:
            pass

        return self.user_defaults.get(param_name) or out_of_box_defaults.get(param_name)


def main(args):
    c = Clusterize(args)


def get_default_config(path):
    if os.path.exists(path):
        print(fore.RED + '{} already exists. delete it first if you want to create a new default config'.format(path) + style.RESET)
        sys.exit()

    config = configparser.ConfigParser()
    config['CLUSTERIZE_DEFAULTS'] = {k: str(v) for k, v in out_of_box_defaults.items()}
    with open(path, 'w') as configfile:
        config.write(configfile)
    print(fore.GREEN + 'default config file written to {}'.format(path) + style.RESET)


if __name__ == '__main__':
    ap = argparse.ArgumentParser("""
    Send commands to the cluster without writing tedious sbatch files. Simply run `clusterize "<your command>"`.
    Which partition, how many cores to use, etc., can all be set explicitly with the parameters below. However,
    if you are using the same parameters over and over again, e.g. you only ever use one partition, then you can
    modify the ~/.cluster_pointer file to point to your specified configuration file. If parameters below are used, they overwrite
    those found in your configuration file. If you need a template, use the --gen-new-config-file command.
    """)

    groupP = ap.add_argument_group('THE COMMAND')
    groupP.add_argument('command', type=str, help='Your bash command that will be submitted as a SLURM job.\
                                                   It must be contained in double quotes, i.e. "<your command>".\
                                                   As an example, `clusterize "echo hello world"`.\
                                                   If the command contains double-quotes, prefix each\
                                                   of them with a backslash, e.g. "echo \\"$(HOME)\\""')

    groupA = ap.add_argument_group('CONFIG', "Some of these options are required, and can be set permanently by\
                                              creating a config file. Generate a config file with --gen-new-config-file,\
                                              modify it to your liking, and then edit ~/.clusterize_pointer so that it points to\
                                              your config file. Any parameter set here overwrites that found in the config file")

    groupA.add_argument('-p','--partition', type=str, help='Which partition of the cluster are you using?')
    groupA.add_argument('-j','--job-name', type=str, help='Give a useful name to your job if you want. This name will show\
                                                           up in the SLURM queue. If --output and --error are not\
                                                           explicitly provided, this parameter will also be their prefix.\
                                                           The default is simply {}'.format(out_of_box_defaults['job_name']))
    groupA.add_argument('-o','--output', type=str, help='Give a name for your output log. By default, its taken from --job-name\
                                                         and equal to the error log file')
    groupA.add_argument('-e','--error', type=str, help='Give a name for your error log. By default, its taken from --job-name\
                                                        and equal to the output log file')
    groupA.add_argument('-x', '--dont-add-random-string-to-job-name-and-outputs', action='store_true', default=None,
                                                      help='By default a unique string is added to job name and the output\
                                                            and error logs. Use this flag to suppress this behavior.')
    groupA.add_argument('-N','--num-nodes', type=int, help='How many nodes you want to use? default is {}'.format(out_of_box_defaults['num_nodes']))
    groupA.add_argument('-n','--num-tasks-per-node', type=int, help='How many nodes you want to use? default {}'.format(out_of_box_defaults['num_tasks_per_node']))
    groupA.add_argument('-t','--allotted-time', help='After this amount of time, the process will be killed :( The \
                                                      default is {}, which could be higher than your cluster allows.\
                                                      One acceptable time format is HH:MM:SS, i.e. 15 hours would\
                                                      be: `15:00:00`'.format(out_of_box_defaults['allotted_time']))
    groupA.add_argument('-M','--mem-per-cpu', type=int, help='How much memory in MB should be allotted per cpu? Default\
                                                              is {}'.format(out_of_box_defaults['mem_per_cpu']))

    groupB = ap.add_argument_group('DEFAULT CONFIG', "Start fresh with a new clusterize config file")
    groupB.add_argument('--gen-new-config-file', type=str, help="If you want to generate a template configuration file,\
                                                      you can do so here. Once you have modified it to your\
                                                      liking, edit the ~/.clusterize_pointer file so that it points to\
                                                      the path of your new configuration file.")

    args = ap.parse_args()

    if args.gen_new_config_file:
        get_default_config(path=args.gen_new_config_file)
    else:
        main(args)

